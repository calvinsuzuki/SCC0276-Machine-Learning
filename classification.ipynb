{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f1a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9a03ca",
   "metadata": {},
   "source": [
    "# Classification of seizures or non seizures by features from EEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32be46f1",
   "metadata": {},
   "source": [
    "### Load npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7df37691",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load(\"seizures_labeled.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac295bd",
   "metadata": {},
   "source": [
    "### Separate features and labels and normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3f0c406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6216, 276)\n",
      "{0.0: 6116, 1.0: 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "x, y = labels[:,:276], labels[:,276]\n",
    "\n",
    "x = preprocessing.normalize(x)\n",
    "print(x.shape)\n",
    "\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c89f67",
   "metadata": {},
   "source": [
    "### Separate in train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e9d77db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3108, 276)\n",
      "(3108,)\n",
      "(3108, 276)\n",
      "(3108,)\n",
      "{0.0: 3051, 1.0: 57}\n",
      "{0.0: 3065, 1.0: 43}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_unb, x_test, y_train_unb, y_test =  train_test_split(x, y, test_size = 0.5, random_state = 0)\n",
    "print(x_train_unb.shape)\n",
    "print(y_train_unb.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "unique, counts = np.unique(y_train_unb, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a3d3d4",
   "metadata": {},
   "source": [
    "### Balancing training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d003cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3108, 277)\n",
      "Before balancing:\n",
      "(3051, 277)\n",
      "(57, 277)\n",
      "After balancing:\n",
      "(3051, 277)\n",
      "(1525, 277)\n",
      "Full data after balancing:\n",
      "(4576, 276)\n",
      "(4576,)\n",
      "{0.0: 3051, 1.0: 1525}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "labels_train = np.hstack((x_train_unb, np.expand_dims(y_train_unb, axis=1)))\n",
    "print(labels_train.shape)\n",
    "\n",
    "non_seizure_idx = np.nonzero(labels_train[:,276] == 0)\n",
    "labels_majority = labels_train[non_seizure_idx]\n",
    "\n",
    "seizure_idx = np.nonzero(labels_train[:,276] == 1)\n",
    "labels_minority = labels_train[seizure_idx]\n",
    "\n",
    "print(\"Before balancing:\")\n",
    "print(np.shape(labels_majority))\n",
    "print(np.shape(labels_minority))\n",
    "\n",
    "labels_minority = resample(labels_minority,\n",
    "                            replace=True,\n",
    "                            n_samples=int(0.5*labels_majority.shape[0]),\n",
    "                            random_state=123)\n",
    "\n",
    "print(\"After balancing:\")\n",
    "print(np.shape(labels_majority))\n",
    "print(np.shape(labels_minority))\n",
    "\n",
    "labels_balanced = np.concatenate((labels_majority, labels_minority))\n",
    "\n",
    "np.random.shuffle(labels_balanced)\n",
    "x_train, y_train = labels_balanced[:,:276], labels_balanced[:,276]\n",
    "\n",
    "print(\"Full data after balancing:\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "# x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size = 0.3)\n",
    "# print(x_train.shape)\n",
    "# print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97120aa",
   "metadata": {},
   "source": [
    "### Filter features by variance and correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9266e1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables Kept after removing features with 0 variance:  276\n",
      "Variables Kept after removing features with corr > 0.9:  275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Calvin\\AppData\\Local\\Temp\\ipykernel_27256\\2929964135.py:9: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# check zero variance features\n",
    "thresholder = VarianceThreshold(threshold=0)\n",
    "print(\"Variables Kept after removing features with 0 variance: \", thresholder.fit_transform(x).shape[1])\n",
    "\n",
    "# highly correlated features\n",
    "corr = abs(pd.DataFrame(x).corr())\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n",
    "cols = [column for column in upper.columns if any(upper[column] < 0.9)]\n",
    "print(\"Variables Kept after removing features with corr > 0.9: \", len(cols)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50da241",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e40ee26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold results\n",
      "[0.9203056768558951, 0.9224043715846995, 0.9169398907103825, 0.9387978142076503, 0.9158469945355191]\n",
      "[0.9372822299651568, 0.9663299663299664, 0.9554140127388535, 0.9404388714733543, 0.9577922077922078]\n",
      "[0.08744038155802862, 0.09870550161812297, 0.10316139767054909, 0.06208053691275168, 0.10543657331136738]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel=\"rbf\", class_weight='balanced', random_state = 0)\n",
    "\n",
    "# cross validation\n",
    "kf = KFold(n_splits=5)\n",
    "accuracy, tpr, fpr = [], [], []\n",
    "for train, test in kf.split(x_train):\n",
    "    svm.fit(x_train[train, :], y_train[train])\n",
    "    pred = svm.predict(x_train[test])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train[test], pred).ravel()\n",
    "    accuracy.append((tp + tn)/(tn + fp + fn + tp))\n",
    "    #print(\"true positive: %.4f\\ntrue negative: %.4f\\nfalse positive: %.4f\\nfalse negative: %.4f\\n\" % (tp, tn, fp, fn))\n",
    "    tpr.append(tp / (tp + fn))\n",
    "    fpr.append(fp / (fp + tn))\n",
    "\n",
    "print(\"KFold results\")\n",
    "print(accuracy)\n",
    "print(tpr)\n",
    "print(fpr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b98fc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Accuracy: 0.93\n",
      "True Positive Rate: 0.07\n",
      "False Positive Rate: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Testing \n",
    "svm.fit(x_train, y_train)\n",
    "pred = svm.predict(x_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(\"Validation\")\n",
    "print(\"Accuracy: %.2f\" % (accuracy))\n",
    "print(\"True Positive Rate: %.2f\" % (tpr))\n",
    "print(\"False Positive Rate: %.2f\" % (fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "65915f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f094945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Calvin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Calvin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Calvin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9832869080779945, 0.9832869080779945, 0.9767873723305478, 0.9693593314763231, 0.9795539033457249]\n",
      "[0.9583333333333334, 0.9789473684210527, 0.905982905982906, 0.8876404494382022, 0.9347826086956522]\n",
      "[0.014271151885830785, 0.016293279022403257, 0.014583333333333334, 0.02327935222672065, 0.016260162601626018]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Calvin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(10, 10), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=False, warm_start=False)\n",
    "\n",
    "# cross validation\n",
    "kf = KFold(n_splits=5)\n",
    "accuracy, tpr, fpr = [], [], []\n",
    "for train, test in kf.split(x_train):\n",
    "    mlp.fit(x_train[train, :], y_train[train])\n",
    "    pred = mlp.predict(x_train[test])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train[test], pred).ravel()\n",
    "    accuracy.append((tp + tn)/(tn + fp + fn + tp))\n",
    "    tpr.append(tp / (tp + fn))\n",
    "    fpr.append(fp / (fp + tn))\n",
    "\n",
    "print(accuracy)\n",
    "print(tpr)\n",
    "print(fpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf3a0a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Accuracy: 0.97\n",
      "True Positive Rate: 0.06\n",
      "False Positive Rate: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Calvin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Testing \n",
    "mlp.fit(x_train, y_train)\n",
    "pred = mlp.predict(x_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(\"Validation\")\n",
    "print(\"Accuracy: %.2f\" % (accuracy))\n",
    "print(\"True Positive Rate: %.2f\" % (tpr))\n",
    "print(\"False Positive Rate: %.2f\" % (fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42592e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9740018570102136, 0.9702878365831012, 0.9740018570102136, 0.9795728876508821, 0.974907063197026]\n",
      "[0.9791666666666666, 0.9789473684210527, 0.9658119658119658, 0.9775280898876404, 0.9782608695652174]\n",
      "[0.026503567787971458, 0.03054989816700611, 0.025, 0.020242914979757085, 0.02540650406504065]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(3)\n",
    "\n",
    "# cross validation\n",
    "kf = KFold(n_splits=5)\n",
    "accuracy, tpr, fpr = [], [], []\n",
    "for train, test in kf.split(x_train):\n",
    "    knn.fit(x_train[train, :], y_train[train])\n",
    "    pred = knn.predict(x_train[test])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train[test], pred).ravel()\n",
    "    accuracy.append((tp + tn)/(tn + fp + fn + tp))\n",
    "    tpr.append(tp / (tp + fn))\n",
    "    fpr.append(fp / (fp + tn))\n",
    "\n",
    "print(accuracy)\n",
    "print(tpr)\n",
    "print(fpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8de818a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Accuracy: 0.96\n",
      "True Positive Rate: 0.00\n",
      "False Positive Rate: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Testing \n",
    "knn.fit(x_train, y_train)\n",
    "pred = knn.predict(x_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(\"Validation\")\n",
    "print(\"Accuracy: %.2f\" % (accuracy))\n",
    "print(\"True Positive Rate: %.2f\" % (tpr))\n",
    "print(\"False Positive Rate: %.2f\" % (fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b4673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "777ff42348a06c70331b54433e37741790203f2b53da2edfdcb6ea943be029bc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
