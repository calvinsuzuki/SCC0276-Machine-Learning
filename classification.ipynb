{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab9a03ca",
   "metadata": {},
   "source": [
    "# Classification of seizures or non seizures by features from EEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600f9fc",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f1a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32be46f1",
   "metadata": {},
   "source": [
    "### Load .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df37691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>FP1-F7_rms</th>\n",
       "      <th>FP1-F7_variance</th>\n",
       "      <th>FP1-F7_kurtosis</th>\n",
       "      <th>FP1-F7_skewness</th>\n",
       "      <th>FP1-F7_max_amp</th>\n",
       "      <th>FP1-F7_min_amp</th>\n",
       "      <th>FP1-F7_n_peaks</th>\n",
       "      <th>FP1-F7_n_crossings</th>\n",
       "      <th>FP1-F7_hfd</th>\n",
       "      <th>...</th>\n",
       "      <th>T8-P8-1_median_freq</th>\n",
       "      <th>T8-P8-1_peak_freq</th>\n",
       "      <th>T8-P8-1_hjorth_mobility</th>\n",
       "      <th>T8-P8-1_hjorth_complexity</th>\n",
       "      <th>T8-P8-1_power_1hz</th>\n",
       "      <th>T8-P8-1_power_5hz</th>\n",
       "      <th>T8-P8-1_power_10hz</th>\n",
       "      <th>T8-P8-1_power_15hz</th>\n",
       "      <th>T8-P8-1_power_20hz</th>\n",
       "      <th>seizure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>3.458339e-09</td>\n",
       "      <td>0.650299</td>\n",
       "      <td>-0.069060</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>-0.00022</td>\n",
       "      <td>91.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.022020</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>219.180264</td>\n",
       "      <td>0.599482</td>\n",
       "      <td>0.270304</td>\n",
       "      <td>0.075103</td>\n",
       "      <td>0.031834</td>\n",
       "      <td>0.023277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>3.422638e-09</td>\n",
       "      <td>0.740510</td>\n",
       "      <td>-0.111613</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>-0.00022</td>\n",
       "      <td>92.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.021621</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>165.246798</td>\n",
       "      <td>0.625755</td>\n",
       "      <td>0.251214</td>\n",
       "      <td>0.072065</td>\n",
       "      <td>0.026998</td>\n",
       "      <td>0.023968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>3.002143e-09</td>\n",
       "      <td>0.966499</td>\n",
       "      <td>0.055559</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>-0.00022</td>\n",
       "      <td>92.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.021733</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>167.521614</td>\n",
       "      <td>0.614227</td>\n",
       "      <td>0.254178</td>\n",
       "      <td>0.074888</td>\n",
       "      <td>0.032268</td>\n",
       "      <td>0.024439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>3.150802e-09</td>\n",
       "      <td>0.687155</td>\n",
       "      <td>0.017912</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>-0.00022</td>\n",
       "      <td>90.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.022694</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>249.743848</td>\n",
       "      <td>0.602653</td>\n",
       "      <td>0.246206</td>\n",
       "      <td>0.085440</td>\n",
       "      <td>0.036898</td>\n",
       "      <td>0.028803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>3.336271e-09</td>\n",
       "      <td>0.547265</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>-0.00022</td>\n",
       "      <td>89.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.022578</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>165.567277</td>\n",
       "      <td>0.623107</td>\n",
       "      <td>0.230839</td>\n",
       "      <td>0.085172</td>\n",
       "      <td>0.034325</td>\n",
       "      <td>0.026558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 508 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_time  FP1-F7_rms  FP1-F7_variance  FP1-F7_kurtosis  FP1-F7_skewness  \\\n",
       "0           0    0.000059     3.458339e-09         0.650299        -0.069060   \n",
       "1           1    0.000058     3.422638e-09         0.740510        -0.111613   \n",
       "2           2    0.000055     3.002143e-09         0.966499         0.055559   \n",
       "3           3    0.000056     3.150802e-09         0.687155         0.017912   \n",
       "4           4    0.000058     3.336271e-09         0.547265         0.001656   \n",
       "\n",
       "   FP1-F7_max_amp  FP1-F7_min_amp  FP1-F7_n_peaks  FP1-F7_n_crossings  \\\n",
       "0         0.00018        -0.00022            91.0                74.0   \n",
       "1         0.00018        -0.00022            92.0                74.0   \n",
       "2         0.00018        -0.00022            92.0                73.0   \n",
       "3         0.00018        -0.00022            90.0                78.0   \n",
       "4         0.00018        -0.00022            89.0                82.0   \n",
       "\n",
       "   FP1-F7_hfd  ...  T8-P8-1_median_freq  T8-P8-1_peak_freq  \\\n",
       "0    0.022020  ...                  2.0                1.0   \n",
       "1    0.021621  ...                  2.0                1.0   \n",
       "2    0.021733  ...                  2.0                1.0   \n",
       "3    0.022694  ...                  2.0                1.0   \n",
       "4    0.022578  ...                  2.0                1.0   \n",
       "\n",
       "   T8-P8-1_hjorth_mobility  T8-P8-1_hjorth_complexity  T8-P8-1_power_1hz  \\\n",
       "0                 0.001255                 219.180264           0.599482   \n",
       "1                 0.001283                 165.246798           0.625755   \n",
       "2                 0.001379                 167.521614           0.614227   \n",
       "3                 0.001496                 249.743848           0.602653   \n",
       "4                 0.001265                 165.567277           0.623107   \n",
       "\n",
       "   T8-P8-1_power_5hz  T8-P8-1_power_10hz  T8-P8-1_power_15hz  \\\n",
       "0           0.270304            0.075103            0.031834   \n",
       "1           0.251214            0.072065            0.026998   \n",
       "2           0.254178            0.074888            0.032268   \n",
       "3           0.246206            0.085440            0.036898   \n",
       "4           0.230839            0.085172            0.034325   \n",
       "\n",
       "   T8-P8-1_power_20hz  seizure  \n",
       "0            0.023277        0  \n",
       "1            0.023968        0  \n",
       "2            0.024439        0  \n",
       "3            0.028803        0  \n",
       "4            0.026558        0  \n",
       "\n",
       "[5 rows x 508 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHANGE THIS PATH FOR THE FOLDER THAT CONTAINS THE .csv FILES OF SPECIFIC PREPROCESSED DATA\n",
    "folder_path = os.path.join('processed_data','chb01_int10_ov00')\n",
    "\n",
    "# paths of all files\n",
    "preproc_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "dataset_list = []\n",
    "for file_path in preproc_files:\n",
    "    # concadenate files\n",
    "    data = pd.read_csv(file_path)\n",
    "    dataset_list.append(data)\n",
    "\n",
    "dataset = pd.concat(dataset_list)\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad24bd52",
   "metadata": {},
   "source": [
    "### Exclude not usefull things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffd09d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.loc[:, dataset.columns != \"seizure\"]\n",
    "x = x.loc[:, x.columns != \"start_time\"]\n",
    "x = x.loc[:, x.columns != \"file ID\"]\n",
    "y = np.asarray(dataset['seizure'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac295bd",
   "metadata": {},
   "source": [
    "### Separate features and labels and normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3f0c406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31044, 506)\n",
      "{0: 30539, 1: 505}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "x = preprocessing.normalize(x)\n",
    "print(x.shape)\n",
    "\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c89f67",
   "metadata": {},
   "source": [
    "### Separate in train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e9d77db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15522, 506)\n",
      "(15522,)\n",
      "(15522, 506)\n",
      "(15522,)\n",
      "{0: 15269, 1: 253}\n",
      "{0: 15270, 1: 252}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_unb, x_test, y_train_unb, y_test =  train_test_split(x, y, test_size = 0.5, random_state = 0)\n",
    "print(x_train_unb.shape)\n",
    "print(y_train_unb.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "unique, counts = np.unique(y_train_unb, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a3d3d4",
   "metadata": {},
   "source": [
    "### Balancing training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d003cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def balance_train_set(x_train_unb, y_train_unb):\n",
    "    labels_train = np.hstack((x_train_unb, np.expand_dims(y_train_unb, axis=1)))\n",
    "    print(labels_train.shape)\n",
    "\n",
    "    non_seizure_idx = np.nonzero(labels_train[:,276] == 0)\n",
    "    labels_majority = labels_train[non_seizure_idx]\n",
    "\n",
    "    seizure_idx = np.nonzero(labels_train[:,276] == 1)\n",
    "    labels_minority = labels_train[seizure_idx]\n",
    "\n",
    "    print(\"Before balancing:\")\n",
    "    print(np.shape(labels_majority))\n",
    "    print(np.shape(labels_minority))\n",
    "\n",
    "    labels_minority = resample(labels_minority,\n",
    "                                replace=True,\n",
    "                                n_samples=int(0.5*labels_majority.shape[0]),\n",
    "                                random_state=123)\n",
    "\n",
    "    print(\"After balancing:\")\n",
    "    print(np.shape(labels_majority))\n",
    "    print(np.shape(labels_minority))\n",
    "\n",
    "    labels_balanced = np.concatenate((labels_majority, labels_minority))\n",
    "\n",
    "    np.random.shuffle(labels_balanced)\n",
    "    x_train, y_train = labels_balanced[:,:276], labels_balanced[:,276]\n",
    "\n",
    "    print(\"Full data after balancing:\")\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "\n",
    "    unique, counts = np.unique(y_train, return_counts=True)\n",
    "    print(dict(zip(unique, counts)))\n",
    "\n",
    "    return x_train, y_train\n",
    "\n",
    "# balance train set\n",
    "# x_train, y_train = balance_train_set(x_train_unb, y_train_unb)\n",
    "\n",
    "x_train, y_train = x_train_unb, y_train_unb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97120aa",
   "metadata": {},
   "source": [
    "### Filter features by variance and correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9266e1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables Kept after removing features with 0 variance:  506\n",
      "Variables Kept after removing features with corr > 0.9:  504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6730/2929964135.py:9: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# check zero variance features\n",
    "thresholder = VarianceThreshold(threshold=0)\n",
    "print(\"Variables Kept after removing features with 0 variance: \", thresholder.fit_transform(x).shape[1])\n",
    "\n",
    "# highly correlated features\n",
    "corr = abs(pd.DataFrame(x).corr())\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "cols = [column for column in upper.columns if any(upper[column] < 0.9)]\n",
    "print(\"Variables Kept after removing features with corr > 0.9: \", len(cols)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d8ea56",
   "metadata": {},
   "source": [
    "## Training and evaluating ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50da241",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e40ee26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM KFold results\n",
      "Accuracy: [0.9867954911433172, 0.9874396135265701, 0.9845360824742269, 0.9871134020618557, 0.9900128865979382]\n",
      "True Positive Rate: [0.9482758620689655, 0.9767441860465116, 0.9642857142857143, 0.9803921568627451, 0.9555555555555556]\n",
      "False Positive Rate: [0.012471283229405973, 0.012410189418680601, 0.015091863517060367, 0.012774320340648543, 0.009480222294867604]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel=\"rbf\", class_weight='balanced', random_state = 0)\n",
    "\n",
    "# cross validation\n",
    "kf = KFold(n_splits=5)\n",
    "accuracy, tpr, fpr = [], [], []\n",
    "for train, test in kf.split(x_train):\n",
    "    svm.fit(x_train[train, :], y_train[train])\n",
    "    pred = svm.predict(x_train[test])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train[test], pred).ravel()\n",
    "    accuracy.append((tp + tn)/(tn + fp + fn + tp))\n",
    "    #print(\"true positive: %.4f\\ntrue negative: %.4f\\nfalse positive: %.4f\\nfalse negative: %.4f\\n\" % (tp, tn, fp, fn))\n",
    "    tpr.append(tp / (tp + fn))\n",
    "    fpr.append(fp / (fp + tn))\n",
    "\n",
    "print(\"SVM KFold results\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"True Positive Rate: {tpr}\")\n",
    "print(f\"False Positive Rate: {fpr}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b98fc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM validation results\n",
      "Accuracy: 0.99\n",
      "True Positive Rate: 0.98\n",
      "False Positive Rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Testing \n",
    "svm.fit(x_train, y_train)\n",
    "pred = svm.predict(x_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(\"SVM validation results\")\n",
    "print(\"Accuracy: %.2f\" % (accuracy))\n",
    "print(\"True Positive Rate: %.2f\" % (tpr))\n",
    "print(\"False Positive Rate: %.2f\" % (fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f094945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guisoares/.virtualenvs/full/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/guisoares/.virtualenvs/full/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/guisoares/.virtualenvs/full/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/guisoares/.virtualenvs/full/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP KFold results\n",
      "Accuracy: [0.9967793880837359, 0.9967793880837359, 0.9945231958762887, 0.9948453608247423, 0.9987113402061856]\n",
      "True Positive Rate: [0.8620689655172413, 0.9069767441860465, 0.8392857142857143, 0.7647058823529411, 0.9111111111111111]\n",
      "False Positive Rate: [0.0006563833278634722, 0.001959503592423253, 0.0026246719160104987, 0.0013101867016049786, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guisoares/.virtualenvs/full/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(10, 10), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=False, warm_start=False)\n",
    "\n",
    "# cross validation\n",
    "kf = KFold(n_splits=5)\n",
    "accuracy, tpr, fpr = [], [], []\n",
    "for train, test in kf.split(x_train):\n",
    "    mlp.fit(x_train[train, :], y_train[train])\n",
    "    pred = mlp.predict(x_train[test])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train[test], pred).ravel()\n",
    "    accuracy.append((tp + tn)/(tn + fp + fn + tp))\n",
    "    tpr.append(tp / (tp + fn))\n",
    "    fpr.append(fp / (fp + tn))\n",
    "\n",
    "\n",
    "print(\"MLP KFold results\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"True Positive Rate: {tpr}\")\n",
    "print(f\"False Positive Rate: {fpr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf3a0a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guisoares/.virtualenvs/full/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP validation results\n",
      "Accuracy: 1.00\n",
      "True Positive Rate: 0.87\n",
      "False Positive Rate: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Testing \n",
    "mlp.fit(x_train, y_train)\n",
    "pred = mlp.predict(x_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(\"MLP validation results\")\n",
    "print(\"Accuracy: %.2f\" % (accuracy))\n",
    "print(\"True Positive Rate: %.2f\" % (tpr))\n",
    "print(\"False Positive Rate: %.2f\" % (fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42592e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN KFold results\n",
      "Accuracy: [0.9938808373590983, 0.9954911433172303, 0.9958118556701031, 0.9967783505154639, 0.9971005154639175]\n",
      "True Positive Rate: [0.6896551724137931, 0.7209302325581395, 0.7678571428571429, 0.803921568627451, 0.8444444444444444]\n",
      "False Positive Rate: [0.0003281916639317361, 0.0006531678641410843, 0.0, 0.0, 0.0006538084341288003]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(3)\n",
    "\n",
    "# cross validation\n",
    "kf = KFold(n_splits=5)\n",
    "accuracy, tpr, fpr = [], [], []\n",
    "for train, test in kf.split(x_train):\n",
    "    knn.fit(x_train[train, :], y_train[train])\n",
    "    pred = knn.predict(x_train[test])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train[test], pred).ravel()\n",
    "    accuracy.append((tp + tn)/(tn + fp + fn + tp))\n",
    "    tpr.append(tp / (tp + fn))\n",
    "    fpr.append(fp / (fp + tn))\n",
    "\n",
    "print(\"KNN KFold results\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"True Positive Rate: {tpr}\")\n",
    "print(f\"False Positive Rate: {fpr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8de818a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN validation results\n",
      "Accuracy: 1.00\n",
      "True Positive Rate: 0.76\n",
      "False Positive Rate: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Testing \n",
    "knn.fit(x_train, y_train)\n",
    "pred = knn.predict(x_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(\"KNN validation results\")\n",
    "print(\"Accuracy: %.2f\" % (accuracy))\n",
    "print(\"True Positive Rate: %.2f\" % (tpr))\n",
    "print(\"False Positive Rate: %.2f\" % (fpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b701c",
   "metadata": {},
   "source": [
    "So we can see that the models were able to learn by the features extracted with the preprocessing notebook. FOr the next steps, we will try to apply models to automatic extract these features and pass it to classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d6df3d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd156d1bfb48eb4ee1a6eb8f39a444f48635a09375c4c26039d85d949812f675"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('full')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
