{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring CHB-MIT dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading edf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = 1\n",
    "DATASET_PATH = os.path.join(os.getcwd(), 'data', 'chb01-summary.txt') #ONLY FOR TESTING\n",
    "patient_id_str = str(patient_id).zfill(2)\n",
    "\n",
    "all_file_path = glob(f'chb{patient_id_str}/*.edf')\n",
    "print(len(all_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_edf(all_file_path[0])\n",
    "print(raw.get_channel_types())\n",
    "print(raw.info)\n",
    "print(raw.ch_names)\n",
    "print(raw.get_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_edf(file_path):\n",
    "    data = mne.io.read_raw_edf(file_path, preload=True)\n",
    "    data.set_eeg_reference()\n",
    "    data.filter(l_freq=0.5, h_freq=45)\n",
    "    epochs = mne.make_fixed_length_epochs(data, duration=10, overlap=1)\n",
    "    epochs_array = epochs.get_data()\n",
    "    return epochs, epochs_array\n",
    "# def read_data_seizures(file_path):\n",
    "#     ref_file = open(file_path, 'r')\n",
    "#     array=epochs.get_data()\n",
    "#     return array\n",
    "\n",
    "def read_edf_to_raw(file_path):\n",
    "    raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "    raw.set_eeg_reference()\n",
    "    raw.filter(l_freq=0.5, h_freq=45)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Shape ()\n",
    "epochs_data_list = [read_data_edf(i)[1] for i in all_file_path]\n",
    "epochs_list = [read_data_edf(i)[0] for i in all_file_path]\n",
    "\n",
    "\n",
    "epochs_data_array = np.array(epochs_data_list)\n",
    "epochs_data_array.shape\n",
    "\n",
    "# merge the files on one array \n",
    "# shape: (N_files, 399 epochs, 23 channels, 2560 values) ->  (N_files*399 epochs, 23 channels, 2560 values)\n",
    "data_array = np.vstack(epochs_data_array)\n",
    "data_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########! Features extraction !#####\n",
    "from scipy import stats\n",
    "def mean(x):\n",
    "    return np.mean(x, axis=-1)\n",
    "def std(x):\n",
    "    return np.std(x, axis=-1)\n",
    "def ptp(x):\n",
    "    return np.ptp(x, axis=-1)\n",
    "def var(x):\n",
    "    return np.var(x, axis=-1)\n",
    "def minim(x):\n",
    "    return np.min(x, axis=-1)\n",
    "def maxim(x):\n",
    "    return np.max(x, axis=-1)\n",
    "def argminim(x):\n",
    "    return np.argmin(x, axis=-1)\n",
    "def argmaxim(x):\n",
    "    return np.argmax(x, axis=-1)\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2, axis=-1))\n",
    "def abs_diff_signal(x):\n",
    "    return np.sum(np.abs(np.diff(x, axis=-1)), axis=-1)\n",
    "def skewness(x):\n",
    "    return stats.skew(x, axis=-1)\n",
    "def kurtosis(x):\n",
    "    return stats.kurtosis(x, axis=-1)\n",
    "def concatenate_features(x):\n",
    "    return np.concatenate((mean(x), std(x), ptp(x), var(x), minim(x), maxim(x), argmaxim(x), \n",
    "                           argminim(x), rms(x), abs_diff_signal(x), skewness(x), kurtosis(x)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for d in data_array:\n",
    "    features.append(concatenate_features(d))\n",
    "    \n",
    "features_array = np.array(features)\n",
    "features_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize features per channel and per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features of specific channel\n",
    "def features_by_channel(features_array):\n",
    "    features_channel = []\n",
    "    MAX_CHANNELS = 23\n",
    "    for i in range(MAX_CHANNELS):\n",
    "        array = features_array[:, i*12:(i+1)*12];\n",
    "        features_channel.append(pd.DataFrame(array, columns=['Mean', 'Std', 'Ptp', 'Var', 'Minimo', 'Maxim', 'Arg Max', 'Arg Min', 'RMS', 'ABS DIFF', 'skewness', 'kurtosis']))\n",
    "    return features_channel\n",
    "\n",
    "features_channel = features_by_channel(features_array)\n",
    "print('Info for channel 23: ')\n",
    "\n",
    "# Shape of features_channel=(23, 1596, 12)\n",
    "features_channel[22].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and labelling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient_folder = Path.cwd()/'chbmit'/'chb{}'.format(str(patient_id).zfill(2))\n",
    "# DATASET_PATH = \n",
    "DATASET_PATH = os.getcwd() #ONLY FOR TESTING\n",
    "\n",
    "patient_id = 1\n",
    "patient_id_str = str(patient_id).zfill(2)\n",
    "\n",
    "patient_folder = os.path.join(DATASET_PATH, f'chb{patient_id_str}')\n",
    "print(f\"Serching for patient {patient_id_str} files at {patient_folder} ...\")\n",
    "patient_files = glob(os.path.join(patient_folder, f'*.edf'))\n",
    "print(f\"Found {len(patient_files)} files\")\n",
    "summary_path = os.path.join(patient_folder, f'chb{patient_id_str}-summary.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## READ SUMMARY (TODO: automate this)\n",
    "seizures_dict = {\"chb01_03\": [[2996, 3036]],\n",
    "                \"chb01_04\": [[1467, 1494]],\n",
    "                \"chb01_15\": [[1732, 1772]],\n",
    "                \"chb01_16\": [[1015, 1066]],\n",
    "                \"chb01_18\": [[1720, 1810]],\n",
    "                \"chb01_21\": [[327, 420]],\n",
    "                \"chb01_26\": [[1862, 1963]],\n",
    "                \n",
    "                \"chb02_16\": [[130, 212]],\n",
    "\n",
    "                \"chb05_06\": [[417, 532]], \n",
    "                \"chb05_13\": [[1086, 1196]],\n",
    "                \"chb05_16\": [[2317, 2413]], \n",
    "                \"chb05_17\": [[2451, 2571]],\n",
    "                \"chb05_22\": [[2348, 2465]],\n",
    "                \n",
    "                \"chb08_02\": [[2670, 2841]], \n",
    "                \"chb08_05\": [[2856, 3046]],\n",
    "                \"chb08_11\": [[2988, 3211]], \n",
    "                \"chb08_13\": [[2417, 2577]],\n",
    "                \"chb08_21\": [[2083, 2347]]}\n",
    "\n",
    "curr_time = 0\n",
    "epoch_time = 10\n",
    "overlap = 5\n",
    "\n",
    "# Divide into epochs\n",
    "labels = []\n",
    "for file_path in patient_files:\n",
    "    # get filename: chbxx_xx.edf\n",
    "    filename = os.path.split(file_path)[1]\n",
    "\n",
    "    # remove .edf staying only chbxx_xx\n",
    "    filename = os.path.splitext(filename)[0]\n",
    "    \n",
    "    # read raw\n",
    "    raw = read_edf_to_raw(file_path)\n",
    "\n",
    "    curr_time = 0\n",
    "    while curr_time <= max(raw.times) + 0.01 - epoch_time:  # max(raw.times) = 3600\n",
    "        epoch_features = []\n",
    "        start_time = curr_time \n",
    "        if start_time < 0.:\n",
    "            start_time = 0.\n",
    "        end_time = curr_time + epoch_time\n",
    "        start, stop = raw.time_as_index([start_time, end_time])\n",
    "        temp = raw[:, start:stop][0]\n",
    "\n",
    "        # start time as ID\n",
    "        # features.append(start_time)\n",
    "\n",
    "        # features\n",
    "        epoch_features.extend(concatenate_features(temp))\n",
    "\n",
    "        # seizure flag for y\n",
    "        aux = []\n",
    "        if filename in seizures_dict:  # if file has seizure\n",
    "            for seizure in seizures_dict[filename]:\n",
    "                if start_time > seizure[0] and start_time < seizure[1]:\n",
    "                    aux.append(1)\n",
    "                elif start_time + epoch_time > seizure[0] and start_time + epoch_time < seizure[1]:\n",
    "                    aux.append(1)\n",
    "                else:\n",
    "                    aux.append(0)\n",
    "        else:    \n",
    "            aux.append(0)\n",
    "\n",
    "        if 1 in aux:\n",
    "            epoch_features.extend([1])\n",
    "        else:\n",
    "            epoch_features.extend([0])\n",
    "\n",
    "        labels.append(epoch_features)\n",
    "\n",
    "        curr_time = curr_time + epoch_time - overlap  \n",
    "        print(\"Section \", str(len(labels)), \"; start: \", start, \" ; stop: \", stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"chb01_10i_5o_wlabel.txt\", np.array(labels), delimiter=\" \")\n",
    "np.save(\"seizures_labeled\", np.array(labels))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
